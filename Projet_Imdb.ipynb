{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Projet_Imdb.ipynb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open in Colab](hhtps://colab.research.google.com/assets/cloab-badge.svg)](https://colab.research.google.com/drive/1DvqoamIBAQ9weAOnIW7ST8e0NHPNam_x)"
      ],
      "metadata": {
        "id": "bUu5oKYl2Lib"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1CbY0LCpr3e",
        "outputId": "b63202f9-3be4-40c5-f56d-f2bec531d1e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchdiffeq in /usr/local/lib/python3.10/dist-packages (0.2.3)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from torchdiffeq) (2.1.0+cu121)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from torchdiffeq) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy>=1.4.0->torchdiffeq) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->torchdiffeq) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->torchdiffeq) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->torchdiffeq) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->torchdiffeq) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->torchdiffeq) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->torchdiffeq) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->torchdiffeq) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->torchdiffeq) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.0->torchdiffeq) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "!pip install torchdiffeq\n",
        "import torchdiffeq\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqMOkR-DwdsS",
        "outputId": "a53789e8-5b94-41cf-d85e-002b17ab6892"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.66.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.31.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.25.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (0.1.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construction du modèle"
      ],
      "metadata": {
        "id": "XgS4lSiZ5h51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from models import ODEBlock\n",
        "from plots import single_feature_plt\n",
        "from dataloaders import ConcentricSphere\n",
        "from training import Trainer\n",
        "from plots import get_feature_history\n",
        "from torch.utils.data import DataLoader\n",
        "from plots import multi_feature_plt\n",
        "from plots import trajectory_plt\n"
      ],
      "metadata": {
        "id": "X6UUpeEqp8Wh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, max_len):\n",
        "        super().__init__()\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        self.pe = torch.zeros(max_len, 1, d_model)\n",
        "        self.pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        self.pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return x"
      ],
      "metadata": {
        "id": "J-zCrRB_AVal"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderMHAttentionODEFunc(nn.Module):\n",
        "    \"\"\"MLP modeling the derivative of FeedForward ODE system.\n",
        "    device : torch.device\n",
        "    data_dim : int\n",
        "        Dimension of data.\n",
        "    hidden_dim : int\n",
        "        Dimension of hidden layers.\n",
        "    augment_dim: int\n",
        "        Dimension of augmentation. If 0 does not augment ODE, otherwise augments\n",
        "        it with augment_dim dimensions.\n",
        "    \"\"\"\n",
        "    def __init__(self, device, data_dim,  augment_dim=0, n_heads=1):\n",
        "        super(EncoderMHAttentionODEFunc, self).__init__()\n",
        "        self.device = device\n",
        "        self.augment_dim = augment_dim\n",
        "        self.data_dim = data_dim\n",
        "        self.input_dim = data_dim + augment_dim\n",
        "        self.nfe = 0  # Number of function evaluations\n",
        "\n",
        "        self.n_heads = n_heads\n",
        "        self.att = nn.MultiheadAttention(self.input_dim, self.n_heads)\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        \"\"\"\n",
        "        t : torch.Tensor (not used here)\n",
        "            Current time. Shape (1,).\n",
        "        x : torch.Tensor\n",
        "            Shape (batch_size, input_dim)\n",
        "        \"\"\"\n",
        "        # Forward pass of model corresponds to one function evaluation, so\n",
        "        # increment counter\n",
        "        self.nfe += 1\n",
        "        x = self.att(x, x, x)[0]\n",
        "        return x\n",
        "\n",
        "class FeedForwardODEFunc(nn.Module):\n",
        "    \"\"\"MLP modeling the derivative of FeedForward ODE system.\n",
        "    device : torch.device\n",
        "    data_dim : int\n",
        "        Dimension of data.\n",
        "    hidden_dim : int\n",
        "        Dimension of hidden layers.\n",
        "    augment_dim: int\n",
        "        Dimension of augmentation. If 0 does not augment ODE, otherwise augments\n",
        "        it with augment_dim dimensions.\n",
        "    \"\"\"\n",
        "    def __init__(self, device, data_dim, hidden_dim, augment_dim=0):\n",
        "        super(FeedForwardODEFunc, self).__init__()\n",
        "        self.device = device\n",
        "        self.augment_dim = augment_dim\n",
        "        self.data_dim = data_dim\n",
        "        self.input_dim = data_dim + augment_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.nfe = 0  # Number of function evaluations\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(self.input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, self.input_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, t, x):\n",
        "        \"\"\"\n",
        "        t : torch.Tensor (not used here)\n",
        "            Current time. Shape (1,).\n",
        "        x : torch.Tensor\n",
        "            Shape (batch_size, input_dim)\n",
        "        \"\"\"\n",
        "        # Forward pass of model corresponds to one function evaluation, so\n",
        "        # increment counter\n",
        "        self.nfe += 1\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "9gAp4vmcqUzL"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlockFunc(nn.Module):\n",
        "  def __init__(self, device, data_dim, hidden_dim, augment_dim=0, n_heads = 1):\n",
        "        super(EncoderBlockFunc, self).__init__()\n",
        "        self.device = device\n",
        "        self.augment_dim = augment_dim\n",
        "        self.data_dim = data_dim\n",
        "        self.input_dim = data_dim + augment_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.nfe = 0  # Number of function evaluations\n",
        "        self.n_heads = n_heads\n",
        "        self.mha = EncoderMHAttentionODEFunc(device, data_dim, augment_dim = augment_dim, n_heads = n_heads)\n",
        "        self.ffd = FeedForwardODEFunc(device, data_dim, hidden_dim, augment_dim=augment_dim)\n",
        "        self.layn1 = nn.LayerNorm(self.input_dim)\n",
        "        self.layn2 = nn.LayerNorm(self.input_dim)\n",
        "\n",
        "  def forward(self, t, x):\n",
        "        \"\"\"\n",
        "        t : torch.Tensor (not used here)\n",
        "            Current time. Shape (1,).\n",
        "        x : torch.Tensor\n",
        "            Shape (batch_size, input_dim)\n",
        "        \"\"\"\n",
        "        # Forward pass of model corresponds to one function evaluation, so\n",
        "        # increment counter\n",
        "        self.nfe += 1\n",
        "        x = self.mha(t,x)\n",
        "        x = self.layn1(x)\n",
        "        x = self.ffd(t,x)\n",
        "        x = self.layn2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "5Mh_uB6p7_lg"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ODETransformerClassification(nn.Module):\n",
        "  def __init__(self, device, seq_len, emb_size,  hidden_dim, n_blocks = 1,  augment_dim=0, n_heads = 1):\n",
        "    super(ODETransformerClassification, self).__init__()\n",
        "    self.device = device\n",
        "    self.seq_len = seq_len\n",
        "    self.emb_size = emb_size\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.augment_dim = augment_dim\n",
        "    self.n_heads = n_heads\n",
        "    ode_blocks = []\n",
        "    for i in range(n_blocks):\n",
        "      encoder_func = EncoderMHAttentionODEFunc(device, emb_size+ 2*i*augment_dim , augment_dim=augment_dim, n_heads=n_heads)\n",
        "      ode_blocks.append(ODEBlock(device, encoder_func, is_seq=True))\n",
        "      ode_blocks.append(nn.LayerNorm(emb_size+ (2*i+1)*augment_dim))\n",
        "      ff_func = FeedForwardODEFunc(device, emb_size+ (2*i+1)*augment_dim, hidden_dim, augment_dim=augment_dim)\n",
        "      ode_blocks.append(ODEBlock(device, ff_func, is_seq=True))\n",
        "      ode_blocks.append(nn.LayerNorm(emb_size+ (2*i+2)*augment_dim))\n",
        "\n",
        "    self.block_layers = nn.Sequential(*ode_blocks)\n",
        "    self.final_layer = nn.Sequential(nn.Linear((emb_size+2*augment_dim*n_blocks)*seq_len, 1), nn.Sigmoid())\n",
        "    self.pos_encoding = PositionalEncoding(emb_size, seq_len)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pos_encoding(x)\n",
        "    x = self.block_layers(x).view(x.shape[0], -1)\n",
        "    return self.final_layer(x)\n",
        "\n",
        "class ODETransformerClassificationAllinOne(nn.Module):\n",
        "  def __init__(self, device, seq_len, emb_size,  hidden_dim, n_blocks = 1,  augment_dim=0, n_heads = 1):\n",
        "    super(ODETransformerClassification, self).__init__()\n",
        "    self.device = device\n",
        "    self.seq_len = seq_len\n",
        "    self.emb_size = emb_size\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.augment_dim = augment_dim\n",
        "    self.n_heads = n_heads\n",
        "    ode_blocks = []\n",
        "    for i in range(n_blocks):\n",
        "      encoder_block = EncoderBlockFunc(device,emb_size+i*augment_dim, hidden_dim,augment_dim=augment_dim, n_heads = n_heads)\n",
        "      ode_blocks.append(ODEBlock(device, encoder_block, is_seq=True))\n",
        "\n",
        "    self.block_layers = nn.Sequential(*ode_blocks)\n",
        "    self.final_layer = nn.Sequential(nn.Linear((emb_size+augment_dim*n_blocks)*seq_len, 1), nn.Sigmoid())\n",
        "    self.pos_encoding = PositionalEncoding(emb_size, seq_len)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pos_encoding(x)\n",
        "    x = self.block_layers(x).view(x.shape[0], -1)\n",
        "    return self.final_layer(x)\n"
      ],
      "metadata": {
        "id": "4SGnQxQBrzV7"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importation des données"
      ],
      "metadata": {
        "id": "1BZT96YG5mgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext as tt\n",
        "\n",
        "emb_dim = 50\n",
        "# Load pre-trained GloVe embeddings\n",
        "glove = tt.vocab.GloVe(name='6B', dim=emb_dim)\n",
        "\n",
        "# Define tokenizer\n",
        "tokenizer = tt.data.utils.get_tokenizer(\"basic_english\")\n",
        "\n",
        "# Define fields for text and label\n",
        "TEXT = tt.data.Field(lower=True, include_lengths=True, batch_first=True, tokenize=tokenizer)\n",
        "LABEL = tt.data.Field(sequential=False)\n",
        "\n",
        "# Define batch size, maximum review length, and maximum vocabulary words\n",
        "batch_size = 64\n",
        "max_review_len = 100\n",
        "max_vocab_words = 3500\n",
        "\n",
        "# Load IMDb dataset\n",
        "train_ds, test_ds = tt.datasets.IMDB.splits(TEXT, LABEL)\n",
        "\n",
        "# Build vocabulary\n",
        "TEXT.build_vocab(train_ds, max_size=max_vocab_words-2)\n",
        "LABEL.build_vocab(train_ds)\n",
        "\n",
        "# Split train dataset into train and dev sets\n",
        "train_ds, dev_ds = train_ds.split(split_ratio=0.8)\n",
        "\n",
        "# Create data iterators\n",
        "train_loader, dev_loader, test_loader = tt.data.BucketIterator.splits(\n",
        "    (train_ds, dev_ds, test_ds),\n",
        "    batch_sizes=(batch_size, batch_size, batch_size),\n",
        "    shuffle=True,\n",
        "    sort_key=lambda x: len(x.text),\n",
        "    sort_within_batch=True,\n",
        "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        ")"
      ],
      "metadata": {
        "id": "cmRQz0DjCB6q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 128\n",
        "# Convert tokenized text into embedded tensors\n",
        "def get_embedded_text(loader):\n",
        "    embedded_texts = []\n",
        "    targets = []\n",
        "    for batch in loader:\n",
        "        text, lengths = batch.text\n",
        "        target = batch.label.unsqueeze(1)\n",
        "        target = torch.where(target == 1, torch.tensor(0.), torch.tensor(1.))  # Add dimension for concatenation\n",
        "\n",
        "\n",
        "        embedded_text = []\n",
        "        for sentence, length in zip(text, lengths):\n",
        "            sentence_emb = []\n",
        "            for i in range(min(length.item(), max_length)):\n",
        "                word = TEXT.vocab.itos[sentence[i]]\n",
        "                try:\n",
        "                    word_emb = glove.vectors[glove.stoi[word]]\n",
        "                except KeyError:\n",
        "                    word_emb = glove.vectors[glove.stoi['unk']]\n",
        "                sentence_emb.append(word_emb)\n",
        "            # Padding\n",
        "            sentence_emb += [torch.zeros(glove.vectors.shape[1])] * (max_length - length)\n",
        "            embedded_text.append(torch.stack(sentence_emb))\n",
        "\n",
        "        embedded_texts.append(torch.stack(embedded_text))\n",
        "        targets.append(target)\n",
        "\n",
        "    embedded_texts = torch.cat(embedded_texts)\n",
        "    targets = torch.cat(targets).squeeze(1)\n",
        "    return embedded_texts, targets\n",
        "\n",
        "\n",
        "# Get embedded tensors for train, dev, and test datasets\n",
        "train_embedded = get_embedded_text(train_loader)\n",
        "print(\"Train embedded text tensor shape:\", train_embedded[0].shape)\n",
        "\n",
        "\n",
        "dev_embedded = get_embedded_text(dev_loader)\n",
        "print(\"Dev embedded text tensor shape:\", dev_embedded[0].shape)\n",
        "\n",
        "test_embedded = get_embedded_text(test_loader)\n",
        "print(\"Test embedded text tensor shape:\", test_embedded[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qGxeRFqCQJq",
        "outputId": "d6975802-e693-41c0-b622-98965f9556bf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train embedded text tensor shape: torch.Size([20000, 128, 50])\n",
            "Dev embedded text tensor shape: torch.Size([5000, 128, 50])\n",
            "Test embedded text tensor shape: torch.Size([25000, 128, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.text = data[0]\n",
        "        self.target = data[1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.text.size(0)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.text[idx], self.target[idx]\n",
        "\n",
        "\n",
        "trainset_embedded = CustomDataset(train_embedded)\n",
        "devset_embedded = CustomDataset(dev_embedded)\n",
        "testset_embedded = CustomDataset(test_embedded)\n",
        "\n",
        "traindataloader_embedded = DataLoader(trainset_embedded, batch_size=32, shuffle=True)\n",
        "testdataloader_embedded = DataLoader(testset_embedded, batch_size=64, shuffle=True)\n",
        "devdataloader_embedded = DataLoader(devset_embedded, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "Xy-ywYStGIQe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrainement et test"
      ],
      "metadata": {
        "id": "aNphhF0H5pLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ODETransformerClassification(device, max_length, emb_dim, 32, augment_dim=16)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "E0A_f0P37UHK"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(dataloader, model, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch in tqdm(dataloader):\n",
        "        inputs, targets = batch\n",
        "        inputs = inputs.to(device)  # Move inputs to GPU if available\n",
        "        targets = targets.to(device)  # Move targets to GPU if available\n",
        "\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        outputs = model(inputs)  # Forward pass\n",
        "        loss = criterion(outputs.view(-1), targets.view(-1))  # Calculate loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        total_loss += loss.item() * len(inputs)\n",
        "        total_samples += len(inputs)\n",
        "\n",
        "    return total_loss / total_samples\n",
        "\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "  loss = train(devdataloader_embedded, model, optimizer, criterion)\n",
        "  print(f\"Epoch {i+1} : Loss = {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX4GHB6_5gIA",
        "outputId": "45f936d8-deeb-4504-a55c-d881ef8699ed"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [03:54<00:00,  2.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 : Loss = 135.11691789855956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [03:55<00:00,  2.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 : Loss = 134.96739652404784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [03:54<00:00,  2.97s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 : Loss = 135.1670230606079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [04:11<00:00,  3.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 : Loss = 135.01730262145995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [04:32<00:00,  3.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 : Loss = 134.96739613342285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [04:21<00:00,  3.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 : Loss = 135.2169287666321\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [04:27<00:00,  3.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 : Loss = 134.9673974029541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [04:29<00:00,  3.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 : Loss = 135.0173027191162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [04:24<00:00,  3.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 : Loss = 135.01730262145995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [04:20<00:00,  3.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 : Loss = 135.06720950012206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total_loss = 0\n",
        "  total = 0\n",
        "  for inputs, targets in tqdm(devdataloader_embedded):\n",
        "    outputs = model(inputs.to(device))\n",
        "    total_loss += criterion(outputs.view(-1), targets.view(-1))*len(inputs)\n",
        "    preds = torch.where(outputs.view(-1) <0.5, torch.tensor(1.), torch.tensor(1.))\n",
        "    correct += torch.sum(preds==targets.view(-1)).item()\n",
        "    total += len(inputs)\n",
        "\n",
        "print(f\"Dev loss : {total_loss/total}\")\n",
        "print(f\"Dev accuracy : {correct/total}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh8qEtXkaaps",
        "outputId": "0888f440-1793-4f2c-e3e3-38e1845e9018"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [01:47<00:00,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dev loss : 135.01731872558594\n",
            "Dev accuracy : 0.5082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}